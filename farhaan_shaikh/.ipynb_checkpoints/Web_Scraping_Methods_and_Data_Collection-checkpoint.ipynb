{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Luther: Web Scraping and Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I will be analyzing data on student and teacher demographics and see if there seems to be any kind of relationship between Illinois teacher demographics and the \"achievement gap\" between hispanic students and their white peers on standardized math tests in high school (The PSAE).\n",
    "\n",
    "This notebook contains the code to scrape the publicly available data from the Illinois Report Card website\n",
    "\n",
    "URL: https://www.illinoisreportcard.com/ListSchools.aspx\n",
    "\n",
    "Analysis will be covered in a second notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Initializing libraries and modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import re\n",
    "import pickle\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selenium Data Scraping Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I decided to use Selenium as my weapon of choice to scrape data because the Illinois Report Card Website has dynamic content that requires quite a bit of clicking**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below opens up a new chrome window from where all the data will be collected. The data collection will be automated through Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chromedriver_path = \"/home/farhaan/chromedriver\"\n",
    "driver = webdriver.Chrome(chromedriver_path)\n",
    "driver.get('https://www.illinoisreportcard.com/ListSchools.aspx')\n",
    "time.sleep(5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web scraping will yield unique dictionaries for each school containing scraped data. All of these dictionaries will be contained within a master_list_of_school_dictionaries until data collection is complete.\n",
    "Once it is complete, the list of dictionaries will be converted into a pandas dataframe object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_list_school_dictionaries = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Navigation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following four functions will contain the means to navigate the website to collect data on each high school. The high schools are organized by alphabet on separate webpages for each alphabet.\n",
    "- Running the **page_navigator** will set the entire data scraping apparatus into motion. It will start at the first webpage with school names beginning with 'A' navigate to the next webpage after all the high school links on the current page have been sorted through and will end at the alphabet 'Z'.\n",
    "- The **link_navigator** will cycle through all the high school school links on the current webpage.\n",
    "    - The **is_highschool** helper function returns a boolean to assist the link_navigator in differentiating high schools from elementary/middle schools.\n",
    "\n",
    "\n",
    "- The **open_school_in_new_tab** function opens the school link in a new tab when the link_navigator has selected a high school. It runs the grab_student_data function on the new tab to collect student data. After data collection for the school has been completed, open_school_in_new_tab closes the tab and returns focus to the main window containing all the school links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def page_navigator():\n",
    "    \"\"\"\n",
    "    will navigate alpha-nav pages while scraping data about every high school\n",
    "    \"\"\"\n",
    "    driver.switch_to_default_content()\n",
    "    alpha_page_list = driver.find_elements_by_xpath('//ul[@class=\"list-inline\"]//a')\n",
    "    alpha_page_index =  0\n",
    "    time.sleep(0.5)\n",
    "    while alpha_page_index < len(alpha_page_list):\n",
    "        alpha_page_list = driver.find_elements_by_xpath('//ul[@class=\"list-inline\"]//a')\n",
    "        if alpha_page_index >0:\n",
    "            next_page=alpha_page_list[alpha_page_index]\n",
    "            next_page.click()\n",
    "            time.sleep(4.5)\n",
    "        link_navigator()\n",
    "        alpha_page_index +=1\n",
    "\n",
    "def link_navigator():\n",
    "    \"\"\"\n",
    "    For the school links on the alpha-nav sorted page, this function\n",
    "    will append scraped data about every high school to\n",
    "    master_list_of_school_dictionaries\n",
    "    \"\"\"\n",
    "    school_list = driver.find_elements_by_xpath('//div[@class=\"col-xs-6 col-sm-6 cellLeft\"]/a')\n",
    "    type_of_school = driver.find_elements_by_xpath('//div[@class=\"col-xs-6 col-sm-6 cellLeft\"]')\n",
    "    time.sleep(0.5)\n",
    "    #slice the type of school list since it contains an extra row for table heading compared to school_list\n",
    "    type_of_school = type_of_school[1:]\n",
    "    #want to only select high schools\n",
    "    for school_type,school_link in zip(type_of_school,school_list):\n",
    "        school_type = school_type.text  \n",
    "        if is_highschool(school_type):\n",
    "            school_data_dict = open_school_in_new_tab(school_link)\n",
    "            if school_data_dict is not None:\n",
    "                master_list_school_dictionaries.append(school_data_dict)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "def is_highschool(school_type):\n",
    "    \"\"\"\n",
    "    based on description on site, checks to see if a given school is a high school\n",
    "    if it is a high school, returns true. if not a high school, returns false.\n",
    "    \"\"\"\n",
    "    it_is_a_highschool = False\n",
    "    regex = re.compile('(.*)\\n.*-12\\)',re.DOTALL|re.MULTILINE)\n",
    "    is_a_highschool_query = re.search(regex,school_type)\n",
    "    if is_a_highschool_query:\n",
    "        it_is_a_highschool = True    \n",
    "    return it_is_a_highschool\n",
    "\n",
    "def open_school_in_new_tab(school_link):\n",
    "    \"\"\"\n",
    "    opens the school link in a new tab, runs data scraping algorithm,\n",
    "    closes the tab, returns the data for the school as a dictionary,\n",
    "    and then switches window focus back to the list of schools\n",
    "    \"\"\"\n",
    "    main_window=driver.current_window_handle\n",
    "    #open the school in a new tab\n",
    "    school_link.send_keys(Keys.CONTROL + Keys.RETURN)\n",
    "    time.sleep(4.5)\n",
    "    #switch to the new tab\n",
    "    driver.switch_to_window(driver.window_handles[-1])\n",
    "    time.sleep(0.5)\n",
    "    #collect the school data\n",
    "    driver.switch_to_default_content()\n",
    "    school_data_dict = grab_school_data()\n",
    "    time.sleep(0.1)\n",
    "    #close the tab and switch focus to the original school list\n",
    "    driver.close()\n",
    "    driver.switch_to_window(main_window)\n",
    "    driver.switch_to_default_content()\n",
    "    return school_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data collection functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following five functions are responsible for extracting the data from each school.\n",
    "For each school, a dictionary will be returned containing:\n",
    "\n",
    "*{School Name, White Hispanic achievement gap, white student demographics, black student demographics, hispanic student demographics, white teacher demographics, black teacher demographics, and hispanic teacher demographics}*\n",
    "\n",
    "- The **grab_school_data** function is the main wrapper for executing the smaller functions. If the *hispanic-white achivement gap* value is not present for a particular school, the function will stop collecting data for that school and return a value of *None* to the open_school_in_new_tab function which originall called grab_school_data.\n",
    "- **grab_achievement_gap** is the gatekeeper. If a grab_achievement_gap value cannot be obtained, there is no point in collecting any more data for the school since the achievement gap **is my output variable of interest**.\n",
    "- **grab_school_name**, **grab_student_ethnicity**, **grab_teacher_ethnicity** are self explanatory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grab_school_data():\n",
    "    \"\"\"\n",
    "    runs a scraping script for a specific school and returns\n",
    "    a dictionary containing desired data in key:value form\n",
    "    \"\"\"\n",
    "    school_data_dict = {}\n",
    "    achievement_gap_val = grab_achievement_gap()\n",
    "    if achievement_gap_val is not None:\n",
    "        school_name = grab_school_name()\n",
    "        student_demographics = grab_student_ethnicity()\n",
    "        teacher_demographics = grab_teacher_ethnicity()\n",
    "        school_data_dict.update(school_name)\n",
    "        school_data_dict['Hispanic_White_Achievement_Gap'] = achievement_gap_val\n",
    "        school_data_dict.update(student_demographics)\n",
    "        school_data_dict.update(teacher_demographics)\n",
    "        return school_data_dict\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def grab_achievement_gap():    \n",
    "    \"\"\"\n",
    "    checks to see if data for the school includes a\n",
    "    white-hispanic standardized test score achievement gap\n",
    "    if it does, this will return the value of the gap.\n",
    "    \"\"\"\n",
    "    students_info = driver.find_element_by_partial_link_text('Academic Progress')\n",
    "    students_info.click()\n",
    "    time.sleep(2)\n",
    "    achievement_gap = driver.find_element_by_partial_link_text('Achievement Gap')\n",
    "    achievement_gap.click()\n",
    "    time.sleep(3.5)\n",
    "    driver.switch_to_frame(driver.find_element_by_name(\"IFrame_IRC\"))\n",
    "    unclick_poverty = driver.find_element_by_xpath('//input[@value=\"LowIncome,NonLowIncome\"]')\n",
    "    unclick_poverty.click()\n",
    "    time.sleep(1.5)\n",
    "    click_hisp_white_gap = driver.find_element_by_xpath('//input[@value=\"Hispanic,White\"]')\n",
    "    click_hisp_white_gap.click()\n",
    "    time.sleep(1.5)\n",
    "    click_math = driver.find_element_by_xpath('//input[@data-value=\"Mathematics\"]')\n",
    "    click_math.click()\n",
    "    time.sleep(2.4)\n",
    "    Hisp_White_Achievement_Gap = driver.find_element_by_xpath('//div[@class=\"result\"]')\n",
    "    time.sleep(0.8)\n",
    "    Hisp_White_Achievement_Gap = Hisp_White_Achievement_Gap.text\n",
    "    regex = re.compile('Hispanic and White\\n(.?[0-9]+)\\n',re.IGNORECASE|re.DOTALL)\n",
    "    if re.search(regex,Hisp_White_Achievement_Gap):\n",
    "        Achievement_Gap_Value = float(re.findall(regex,Hisp_White_Achievement_Gap)[0])\n",
    "        driver.switch_to_default_content()\n",
    "        return Achievement_Gap_Value\n",
    "    else:\n",
    "    # If we can't grab data on the achievement gap, we will just be\n",
    "    #check the next school in our list\n",
    "        driver.switch_to_default_content()\n",
    "        return None\n",
    "\n",
    "def grab_school_name():\n",
    "    \"\"\"\n",
    "    returns school name as a single key:value dictionary\n",
    "    \"\"\"\n",
    "    school_name_dict={}\n",
    "    school_name = driver.find_element_by_xpath('//section[@class=\"main-content\"]//span[@class=\"lblHeader\"]')\n",
    "    time.sleep(0.4)\n",
    "    school_name_dict['school_name'] = school_name.text\n",
    "    driver.switch_to_default_content()    \n",
    "    return school_name_dict\n",
    "\n",
    "def grab_student_ethnicity():\n",
    "    \"\"\"\n",
    "    returns black, white, and hispanic student demographics as a dictionary\n",
    "    \"\"\"\n",
    "    student_demographics = {}\n",
    "    time.sleep(0.2)\n",
    "    students_info = driver.find_element_by_partial_link_text('Students')\n",
    "    students_info.click()\n",
    "    time.sleep(2.5)\n",
    "    student_ethnicity = driver.find_element_by_partial_link_text('Racial/Ethnic Diversity')\n",
    "    student_ethnicity.click()\n",
    "    time.sleep(4.5)\n",
    "    driver.switch_to_frame(driver.find_element_by_name(\"IFrame_IRC\"))\n",
    "    time.sleep(0.4)\n",
    "    graph_info = driver.find_element_by_xpath('//div[@id=\"graph-data\"]')\n",
    "    time.sleep(0.8)\n",
    "    graph_info_text = graph_info.text\n",
    "    regex = re.compile('White \\(([0-9]+\\.*[0-9]*)%\\)',re.IGNORECASE|re.DOTALL)\n",
    "    student_demographics['white_students'] = float(re.findall(regex,graph_info_text)[0])\n",
    "    regex = re.compile('Black \\(([0-9]+\\.*[0-9]*)%\\)',re.IGNORECASE|re.DOTALL)\n",
    "    student_demographics['black_students'] = float(re.findall(regex,graph_info_text)[0])   \n",
    "    regex = re.compile('Hispanic \\(([0-9]+\\.*[0-9]*)%\\)',re.IGNORECASE|re.DOTALL)\n",
    "    student_demographics['hispanic_students'] = float(re.findall(regex,graph_info_text)[0])\n",
    "    driver.switch_to_default_content()\n",
    "    return student_demographics\n",
    "    \n",
    "\n",
    "def grab_teacher_ethnicity():\n",
    "    \"\"\"\n",
    "    returns black, white, and hispanic teacher demographics as a dictionary\n",
    "    \"\"\"\n",
    "    teacher_demographics = {}\n",
    "    time.sleep(0.1)\n",
    "    teachers_info = driver.find_element_by_partial_link_text('Teachers')\n",
    "    teachers_info.click()\n",
    "    time.sleep(2.5)\n",
    "    achievement_gap = driver.find_element_by_partial_link_text('Demographics')\n",
    "    achievement_gap.click()\n",
    "    time.sleep(4.9)\n",
    "    driver.switch_to_frame(driver.find_element_by_name(\"IFrame_IRC\"))\n",
    "    time.sleep(0.4)\n",
    "    graph_info = driver.find_element_by_xpath('//div[@id=\"nested-graph\"]')\n",
    "    time.sleep(0.8)\n",
    "    graph_info_text = graph_info.text\n",
    "    regex = re.compile('White \\(([0-9]+\\.*[0-9]*)%\\)',re.IGNORECASE|re.DOTALL)\n",
    "    temp_re = re.findall(regex,graph_info_text)\n",
    "    teacher_demographics['white_teachers'] = float(temp_re[0])\n",
    "    regex = re.compile('Black \\(([0-9]+\\.*[0-9]*)%\\)',re.IGNORECASE|re.DOTALL)\n",
    "    temp_re = re.findall(regex,graph_info_text)\n",
    "    teacher_demographics['black_teachers'] = float(temp_re[0])   \n",
    "    regex = re.compile('Hispanic \\(([0-9]+\\.*[0-9]*)%\\)',re.IGNORECASE|re.DOTALL)\n",
    "    temp_re = re.findall(regex,graph_info_text)\n",
    "    teacher_demographics['hispanic_teachers'] = float(temp_re[0])\n",
    "    driver.switch_to_default_content()\n",
    "    return teacher_demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To scrape the data, all that needs to be done is run the **page_navigator**. All data will be collected within list element *master_list_of_school_dictionaries*.\n",
    "\n",
    "Caution: A nasty NoSuchElementFound Error will occur if your internet connection is too slow to load the dynamic javascript based webpage content before the script searches for certain elements. A fix for this would be:\n",
    "\n",
    "a. to increase sleep times in certain parts of the script\n",
    "\n",
    "b. Better method: use the WebDriverWait function in conjunction with the expected_conditions module from the appropriate Selenium packages which will wait until an element is loaded for a user-specified time before python throws an error.\n",
    "    - This is considered best practice.\n",
    "    - time.sleep() works but is not best practice (allegedly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Running this function is all that is needed to collect all the data\n",
    "page_navigator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickling Data and formatting it for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable *master_list_of_school_dictionaries* contains dictionaries of all the schools.\n",
    "we can turn our data into a dataframe by turning the list of dictionaries into a dictionary of lists and then using the pandas module to convert it into a dataframe.\n",
    "The resulting dataframe will be pickled for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_of_dicts_to_dict_of_lists(list_of_dicts):\n",
    "    \"\"\"\n",
    "    Turns a list of dictionaries with common keys into one dictionary containing\n",
    "    a list of valuse for each key. This makes it easy to create a dataframe object.\n",
    "    \"\"\"\n",
    "    dict_of_lists = collections.defaultdict(list)\n",
    "    for dictionary in list_of_dicts:\n",
    "        for key, value in dictionary.items():\n",
    "            dict_of_lists[key].append(value)\n",
    "    return dict_of_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "master_list_of_school_dictionaries is a <class 'list'>\n",
      "student_data_df is a <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(\"master_list_of_school_dictionaries is a\",type(master_list_of_school_dictionaries))\n",
    "pre_df_student_data = list_of_dicts_to_dict_of_lists(master_list_of_school_dictionaries)\n",
    "student_data_df = pd.DataFrame(pre_df_student_data)\n",
    "print(\"student_data_df is a\",type(student_data_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickling the DataFrame to filename:\n",
    "**student_data_df_pickle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.to_pickle(student_data_df,'/home/farhaan/ds/metis/metisgh/Projects/02-Luther/student_data_df_pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
